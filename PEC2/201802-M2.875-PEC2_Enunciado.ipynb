{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875 · Deep Learning · PEC2</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2018-2 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Alumno: <b>Fernando Antonio Barbeiro Campos</b> - <a>fbarbeiro@uoc.edu</a></p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PEC2: Redes Neuronales Convolucionales con KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a implementar dos redes neuronales convolucionales para reconocer los dígitos del conjunto de datos de referencia MNIST. Además, entrenaremos también un modelo sencillo de super-resolución. En concreto se implementarán los siguientes tres puntos:\n",
    "\n",
    "1. Una red neuronal convolucional de una capa\n",
    "2. Una red neuronal convolucional profunda con x capas\n",
    "3. Un modelo de super-resolución\n",
    "\n",
    "En los tres casos se utilizará la librería Keras para la implementación del modelo, la compilación y el entrenamiento. A continuación utulizaremos también Keras para predecir la clasificación de imágenes del conjunto de test.\n",
    "\n",
    "**Importante: Cada uno de los ejercicios puede suponer varios minutos de ejecución, por lo que la entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Inicialización y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código carga los paquetes necesarios para la práctica y además lee los datos que utilizaremos para entrenar la red neuronal. El Dataset MNIST corresponde a imágenes de digitos del 0 al 9 de tamaño 28x28 píxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 28s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# Descarga de el dataset MNIST y hace la partición train/test\n",
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizamos la primera imagen del dataset\n",
    "first_image = x_train_orig[0]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobación del tamaño de la imagen\n",
    "x_train_orig[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Red Neuronal Convolucional de una capa [4 puntos]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación implementaremos una red neuronal convolucional de una capa y haremos el entrenamiento y test sobre el dataset MNIST. Tenemos 60000 imágenes para entrenar y 10000 para testear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-procesado de datos\n",
    "\n",
    "El primer paso para entrenar una red neuronal consiste en pre-procesar los datos de entrenamiento y test para que cuadren con el input de la red neuronal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [0,5 pts.]:</strong> Ajustar el tamaño de los datos de entrenamiento y test utilizando 4 dimensiones (la última dimnesión tiene que ser 1 para indicar que las imágenes están en escala de grises). TIP: utilitar el número de datos de entrenamiento y test y el tamaño de las imágenes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando TIP: ([0] - numero imagenes, [28, 28, 1] - tamaño, gris)\n",
    "\n",
    "x_train = x_train_orig.reshape(x_train_orig.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test_orig.reshape(x_test_orig.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# Normalizando de 0-255 a 0-1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [0,5 pts.]:</strong> Codificar los valores de las etiquetas de salida en un vector one-hot. Por ejemplo, el vector de salida para una imagen que contiene un 5 sería: [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]. TIP: se puede utilizar la función to_categorical de Keras.utils. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "y_train = to_categorical(y_train_orig)\n",
    "y_test = to_categorical(y_test_orig)\n",
    "\n",
    "# Lo sé que está definida num_classes abajo, esa es para confirmación\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creación del modelo\n",
    "\n",
    "\n",
    "Vamos a usar un modelo Secuencial de Keras ya que es muy fácil de utilizar. Este tipo de modelos nos permiten construir el modelo capa a capa. En concreto:\n",
    "\n",
    "- La primera capa que añadiremos será una capa convolucional con las siguientes propiedades: \n",
    "    - Número de kernels (neuronas) primera capa: 64 neuronas\n",
    "    - Tamaño de los kernels: 3x3\n",
    "    - Activacion de los kernels: ReLU\n",
    "- A continuación añadiremos una capa Flatten para conectar la salida de la capa convolucional con la entrada de una capa densa.\n",
    "- Por último, añadiremos una capa densa de salida, y por lo tanto tendrá tantas neuronas como clases queremos predecir. La activación de esta última capa sera Softmax. La predicción final del modelo será entonces la clase que tenga una probabilidad más alta. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [2 pts.]:</strong> Construir el modelo según los requerimientos indicados.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentado el num_classes pq fue definido arriba\n",
    "# num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Compilación el modelo\n",
    "\n",
    "Una vez definido el modelo se tiene que compilamos para que Keras prepare el entrenamiento. Para ello vamos a utilizar el algoritmo de optimización ADAM, la función de coste \"categorical_crossentropy\" y la métrica \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Entrenamiento del modelo\n",
    "\n",
    "Entrenamos ahora el modelo. Para ello haremos que el modelo vea cada imagen 9 veces distintas, y utilizaremos el conjunto de test para la validación del proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [0,5 pts.]:</strong> Entrenar el modelo durante 9 epochs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/9\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.2633 - acc: 0.9266 - val_loss: 0.1079 - val_acc: 0.9685\n",
      "Epoch 2/9\n",
      "60000/60000 [==============================] - 21s 351us/step - loss: 0.0863 - acc: 0.9755 - val_loss: 0.0708 - val_acc: 0.9774\n",
      "Epoch 3/9\n",
      "60000/60000 [==============================] - 20s 341us/step - loss: 0.0585 - acc: 0.9830 - val_loss: 0.0624 - val_acc: 0.9814\n",
      "Epoch 4/9\n",
      "60000/60000 [==============================] - 20s 336us/step - loss: 0.0463 - acc: 0.9863 - val_loss: 0.0611 - val_acc: 0.9801\n",
      "Epoch 5/9\n",
      "60000/60000 [==============================] - 20s 337us/step - loss: 0.0370 - acc: 0.9890 - val_loss: 0.0585 - val_acc: 0.9815\n",
      "Epoch 6/9\n",
      "60000/60000 [==============================] - 20s 336us/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0569 - val_acc: 0.9827\n",
      "Epoch 7/9\n",
      "60000/60000 [==============================] - 20s 337us/step - loss: 0.0257 - acc: 0.9925 - val_loss: 0.0621 - val_acc: 0.9813\n",
      "Epoch 8/9\n",
      "60000/60000 [==============================] - 21s 344us/step - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0595 - val_acc: 0.9822\n",
      "Epoch 9/9\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0189 - acc: 0.9944 - val_loss: 0.0600 - val_acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12efd6080>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento del modelo\n",
    "n_epochs_onelayer = 9\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=n_epochs_onelayer, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5  Evolución de la precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [0,5 pts.]:</strong> Visualizar la evolución del accuracy en el conjunto de entrenamiento y de test en función de las épocas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: plot del training loss y el accuracy\n",
    "def plot_prediction(n_epochs, mfit):\n",
    "\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(n_epochs_onelayer, mfit_onelayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Predicción\n",
    "\n",
    "Finalmente podemos hacer la predicción para cuatro de las imágenes del conjunto de test y mirar si los resultados son o no correctos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la predicción para las 4 primeras imágenes del set de test\n",
    "print(model.predict(x_test[:4]))\n",
    "\n",
    "# Mostramos el ground truth para las primeras 4 imágenes\n",
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deep CNN + Dropout [3 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejercicio anterior hemos implementado una red convolucional de una sola capa. Ahora vamos a implementar una red neuronal convolucional profunda y veremos como ésto se traduce en un mejor rendimiento en los resultados. Primero inicializaremos y pre-procesaremos los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [0,5 pts.]:</strong> Codificar los valores de las etiquetas de salida en un vector one-hot. TIP: se puede utilizar la función to_categorical de Keras.utils. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso volveremos a utilizar un modelo Sequential de Keras que constará de: \n",
    "- Dos capas de convolución de 32 y 64 kernels respectivamente de tamaño 3x3, y con función de activación relu\n",
    "- Una capa de MaxPooling con un tamaño de 2x2\n",
    "- Una capa de Dropout con un rate=0.25\n",
    "- Una capa Flatten\n",
    "- Una capa densa con 128 neuronas y función de activación relu\n",
    "- Una capa de Dropout con un rate=0.5\n",
    "- Una capa densa con función de activación softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [1,5 pts.]:</strong> Implementar la arquitectura de la red neuronal con las características indicadas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO construir la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación compilamos, entrenamos y evaluamos el modelo. Para la compilación volveremos a utilizar la función de coste \"categorical_crossentropy\" y la métrica \"accuracy\", pero en este caso utilizaremos el optimizador Adadelta.\n",
    "\n",
    "El entrenamiento del modelo lo haremos durante 12 épocas, utilizando un batch_size de 128, y el conjunto de test para validar. Finalmente utilizaremos también el conjunto de test para evaluar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [0,5 pts.]:</strong> Entrenar el modelo durante 12 épocas, con un batch_size de 128, y el conjunto de test como validación. La función de coste tiene que ser \"categorical_crossentropy\", el optimizador Adadelta i hay que mostrar la métrica \"accuracy\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None\n",
    "n_epochs = None \n",
    "\n",
    "model.compile(None) \n",
    "\n",
    "mfit = None \n",
    "\n",
    "\n",
    "#Evaluación el modelo sobre el conjunto de test\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizción de la evolución de la métrica accuracy\n",
    "plot_prediction(n_epochs, mfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir las cuatro primeras imágenes del conjunto de test\n",
    "print(model.predict(x_test[:4]))\n",
    "y_test[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Análisis [0,5 pts.]:</strong> Analizar los resultados obtenidos y la variación del tiempo de entrenamiento entre el modelo de una capa y el de diversas capas. Comentar posibles mejoras del modelo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN aplicada a super resolución de imágenes [3 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio construiremos una red neuronal convolucional tal que, dadas unas imágenes de baja resolución, nos permita obtener las mismas imágenes pero con una resolución más alta. Para ello, a partir del mismo conjunto de datos MNIST crearemos imágenes de baja resolución con las cuales vamos a entrenar nuestro modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar reducimos la resolución de las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_orig[:, ::2, ::2]\n",
    "x_test = x_test_orig[:, ::2, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y normalizamos los valores de los píxeles y ajustamos las dimensiones de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los valores de los píxeles\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "y_train = x_train_orig / 255.0\n",
    "y_test = x_test_orig / 255.0\n",
    "\n",
    "# Ajustamos las dimensiones de los datos\n",
    "x = np.expand_dims(x_train, axis=3)\n",
    "y = np.expand_dims(y_train, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creación y entrenamiento del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación crearemos y entrenaremos el modelo con las siguientes características:\n",
    "\n",
    "- Una capa convolucional de 32 kernels de tamaño 3x3, y con función de activación relu.\n",
    "- Una capa de MaxPooling con un tamaño de 2x2.\n",
    "- Otra capa convolucional de 32 kernels de tamaño 3x3, y con función de activación relu.\n",
    "- Una capa deconvolucional con 32 kernels, de tamaño 3x3, stride 2x2, y función de activación relu.\n",
    "- Una última capa deconvolucional con un único kernel de tamaño 3x3, stride 2x2, y función de activación sigmoid.\n",
    "\n",
    "Todas las capas convolucionales y deconvolucionales tienen que tenen el parámetro padding \"sames\", de forma que el tamaño de las imágenes no se vea afectado en estas capas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [2 pts.]:</strong> Crear y entrenar el modelo según las características indicadas. Podéis probar diferentes números de épocas para intentar obtener los mejores resultados posibles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Creación del modelo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Entrenar y compilar el modelo\n",
    "model.compile(None)\n",
    "model.fit(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Predicción de algunas imágenes del conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "<strong>Ejercicio [1 pto.]:</strong> Visualizar tres imágenes al azar del conjunto de test. Mostrar la versión original de la imagen, la versión con resolución reducida, y la predicción del modelo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción de tres imágenes del conjunto de test\n",
    "n_images = None\n",
    "idx_images = np.random.randint(x_test.shape[0], size=n_images)\n",
    "\n",
    "images = np.expand_dims(np.stack([x_test[i] for i in idx_images]), axis=3)\n",
    "\n",
    "pred = model.predict(images)\n",
    "\n",
    "# Ajustamos las dimensiones de las imágenes predichas al formato adecuado y desnormalizamos los píxeles\n",
    "pred = None\n",
    "\n",
    "##TODO: Visualización de las imágenes predichas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
